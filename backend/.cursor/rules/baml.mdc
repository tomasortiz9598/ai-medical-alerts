---
description: A set of rules for setting up BAML and help with syntax guidance.
globs: **/baml_src/*.baml
alwaysApply: false
---

<Overview>
  BAML (Basically, A Made-Up Language) is a domain-specific language for building LLM prompts as functions.
  You can build an agentic workflow with BAML.
</Overview>

  <Schema>
    // Define output schemas using classes
    class MyObject {
      // Optional string fields use ?
      // @description is optional, but if you include it, it goes after the field.
      name string? @description("The name of the object")
      
      // Arrays of primitives
      // arrays cannot be optional.
      tags string[]
      
      // Enums must be declared separately and are optional
      status MyEnum?
      
      // Union types
      type "success" | "error"
      
      // Primitive types
      count int
      enabled bool
      score float

      // nested objects
      nested MyObject2

      // image type
      myImg image

      {#// checks and assertions. Uses jinja syntax inside the parentheses.
      // For a single property use one @
      bar int @assert(between_0_and_10, {{ "{{ this > 0 and this < 10 }}" }}) //this = MyObject.bar value
      quux string
      // assertions for multiple fields use @@ and go at the bottom of the class. Uses jinja syntax inside the parentheses.
      // Do NOT add descriptions after the assertion.
      @@assert(length_limit, {{ "{{ this.quux|length < this.baz }}" }})#}
    }

    // Enums are declared separately
    enum MyEnum {
      PENDING
      ACTIVE @description("Item is currently active")
      COMPLETE
    }

    // Comments use double slashes
    // Recursive types and inline definitions are not supported

  </Schema>

  <Functions>
    // Functions define inputs, outputs and prompts
    // function name is always PascalCase
    function MyFunction(input: MyObject) -> string {
      client "openai/gpt-4o"
      // prompt with jinja syntax inside here. with double curly braces for variables.
      // make sure to include: \{\{ ctx.output_format \}\} in the prompt, which prints the output schema instructions so the LLM returns the output in the correct format (json or string, etc.). DO NOT write the output schema manually.
      prompt #"
        
      "#
    }

    <LLMClients>
      You can use any of the following:
      - openai/gpt-4o
      - openai/gpt-4o-mini
      - anthropic/claude-3-5-sonnet-latest (note the "3-5")
      - anthropic/claude-3-5-haiku-latest
    </LLMClients>

    <Prompt>
      When writing the prompt:
      1. Make sure to include the input in the prompt (even if it's an image) using {{ "{{ input }}" }}
      2. Make sure to include {{ "{{ ctx.output_format }}" }} in the prompt so the LLM knows how to format the output.
      3. You do not need to specify to "answer in JSON format". Only write in the prompt brief instruction, and any other task-specific things to keep in mind for the task.
      4. Write a {{ "{{ _.role(\"user\") }}" }} tag to indicate where the user's inputs start. So if there's a convo you can write
      #"{{ "{{ _.role(\"user\") }}" }} {{ "{{ some-variable }}" }}#

      DO NOT REPEAT output schema fields in the prompt. They are included with {{ "{{ ctx.output_format }}" }}.
      ```baml
      class TweetAnalysis {
        mainTopic string @description("The primary topic or subject matter of the tweet")
        isSpam bool @description("Whether the tweet appears to be spam")
      }

      function ClassifyTweets(tweets: string[]) -> TweetAnalysis[] {
        client "openai/gpt-4o-mini"
        prompt #"
          Analyze each of the following tweets and classify them:
          {{ "{{ _.role(\"user\") }}" }} {{ "{{ tweets }}" }}

          {{ "{{ ctx.output_format }}" }}
        "#
      }
      ```
    </Prompt>

  </Functions>

  <Usage in other languages>
    You can use BAML in python, typescript, and other languages.

    ```python
    import asyncio
    from baml_client import b // this client is autogenerated
    from baml_client.types import WeatherAPI

    def main():
        # In python, BAML functions are synchronous.
        weather_info = b.UseTool("What's the weather like in San Francisco?")
        print(weather_info)
        assert isinstance(weather_info, WeatherAPI)
        print(f"City: {weather_info.city}")
        print(f"Time of Day: {weather_info.timeOfDay}")

    if __name__ == '__main__':
        main()
    ```

    ```typescript
    import { b } from './baml_client' // this client is autogenerated
    import { WeatherAPI } from './baml_client/types'
    import assert from 'assert'

    const main = async () => {
      const weatherInfo = await b.UseTool("What's the weather like in San Francisco?")
      console.log(weatherInfo)
      assert(weatherInfo instanceof WeatherAPI)
      console.log(`City: ${weatherInfo.city}`)
      console.log(`Time of Day: ${weatherInfo.timeOfDay}`)
        }
    ```

  </Usage>

  <baml_client>
    The baml_client is the auto-generated client that allows you to call your BAML functions from your application code.

    <ClientTypes>
      BAML provides both synchronous and asynchronous clients:
      
      ```python
      from baml_client import b  # Synchronous client
      from baml_client.async_client import b as async_b  # Asynchronous client
      
      # Synchronous call
      result = b.MyFunction(input_data)
      
      # Asynchronous call  
      result = await async_b.MyFunction(input_data)
      ```

      ```typescript
      import { b } from './baml_client'  // Async client (default)
      
      // All calls are async in TypeScript
      const result = await b.MyFunction(inputData)
      ```
    </ClientTypes>

    <Configuration>
      You can configure client behavior using with_options():
      
      ```python
      from baml_client import b
      from baml_client.types import ClientOptions
      
      # Override default client settings
      result = b.MyFunction.with_options(
          client_options=ClientOptions(
              max_retries=3,
              timeout_ms=30000,
              temperature=0.7
          )
      )(input_data)
      ```

      ```typescript
      import { b } from './baml_client'
      
      const result = await b.MyFunction.withOptions({
          clientOptions: {
              maxRetries: 3,
              timeoutMs: 30000,
              temperature: 0.7
          }
      })(inputData)
      ```
    </Configuration>

    <ErrorHandling>
      BAML provides specific error types for better error handling:
      
      ```python
      from baml_client import b
      from baml_client.errors import (
          BamlValidationError,
          BamlClientFinishReasonError
      )
      
      try:
          result = b.MyFunction(input_data)
      except BamlValidationError as e:
          # Handle output validation errors
          print(f"Validation error: {e}")
      except BamlClientFinishReasonError as e:
          # Handle LLM finish reason errors (e.g., content filter)
          print(f"Finish reason error: {e}")
      ```
    </ErrorHandling>

    <Streaming>
      For functions that support streaming, use the stream methods:
      
      ```python
      from baml_client import b
      
      # Streaming in Python
      for chunk in b.MyStreamingFunction.stream(input_data):
          print(chunk)
      ```

      ```typescript
      import { b } from './baml_client'
      
      // Streaming in TypeScript
      const stream = b.MyStreamingFunction.stream(inputData)
      for await (const chunk of stream) {
          console.log(chunk)
      }
      ```
    </Streaming>

    <MediaHandling>
      BAML supports various media types (images, audio, PDFs, videos):
      
      ```python
      from baml_client import b
      from baml_client.types import BamlImage, BamlAudio, BamlPdf
      
      # Handle images
      image = BamlImage.from_path("./image.jpg")
      # or from URL
      image = BamlImage.from_url("https://example.com/image.jpg")
      # or from base64
      image = BamlImage.from_base64("image/jpeg", "...")
      
      result = b.AnalyzeImage(image)
      ```

      ```typescript
      import { b, BamlImage } from './baml_client'
      
      // Handle images
      const image = BamlImage.fromPath("./image.jpg")
      // or from URL
      const image = BamlImage.fromUrl("https://example.com/image.jpg")
      
      const result = await b.AnalyzeImage(image)
      ```
    </MediaHandling>

    <ReactIntegration>
      For React/Next.js applications, BAML generates hooks:
      
      ```typescript
      import { useMyFunction } from './baml_client/react'
      
      function MyComponent() {
          const { data, loading, error, trigger } = useMyFunction()
          
          const handleSubmit = async (inputData) => {
              await trigger(inputData)
          }
          
          if (loading) return <div>Loading...</div>
          if (error) return <div>Error: {error.message}</div>
          
          return (
              <div>
                  <button onClick={() => handleSubmit(someData)}>
                      Call Function
                  </button>
                  {data && <div>Result: {JSON.stringify(data)}</div>}
              </div>
          )
      }
      ```
    </ReactIntegration>

    <Collector>
      Use Collector to track token usage and other metrics:
      
      ```python
      from baml_client import b
      from baml_client.collector import Collector
      
      collector = Collector()
      result = b.MyFunction.with_options(
          collector=collector
      )(input_data)
      
      # Access collected metrics
      print(f"Tokens used: {collector.total_tokens}")
      print(f"Cost: ${collector.total_cost}")
      ```
    </Collector>

    <DynamicTypes>
      Create types dynamically using TypeBuilder:
      
      ```python
      from baml_client.type_builder import TypeBuilder
      
      # Build a dynamic class
      tb = TypeBuilder()
      tb.class_("DynamicClass")
      tb.field("name", "string")
      tb.field("age", "int")
      dynamic_type = tb.build()
      
      # Use with functions
      result = b.MyFunction.with_options(
          tb=tb
      )(input_data)
      ```
    </DynamicTypes>

    <ClientRegistry>
      Access and configure LLM clients at runtime:
      
      ```python
      from baml_client.registry import get_client_registry
      
      registry = get_client_registry()
      
      # Get available clients
      clients = registry.list_clients()
      
      # Override client configuration
      registry.set_primary("my_client", {
          "api_key": "new_key",
          "base_url": "https://custom-endpoint.com"
      })
      ```
    </ClientRegistry>

  </baml_client>

Do NOT use numbers as confidence intervals if you need to use them. Prefer an enum with descriptions or literals like "high", "medium", "low".
Don't add confidence levels to extraction schemas.

Don't use LLM functions to "validate" any other output. {#You should use @assert for that on each field in the output type. Search the docs for "assert" to see how to use it.#}

Dedent all declarations.

Note that the types exported by BAML are pydantic classes in python, and interfaces in Tyepscript, except for primitive types.