# ----------------------------------------------------------------------------
#
#  Welcome to Baml! To use this generated code, please run the following:
#
#  $ pip install baml
#
# ----------------------------------------------------------------------------

# This file was generated by BAML: please do not edit it. Instead, edit the
# BAML files and re-generate this code using: baml-cli generate
# baml-cli is available with the baml package.

_file_map = {
    "clients.baml": '// Learn more about clients at https://docs.boundaryml.com/docs/snippets/clients/overview\n\n// Cost-optimised OpenAI Responses client for structured JSON output\nclient<llm> OpenAIResponsesStable {\n  provider openai-responses\n  options {\n    model "gpt-4o-mini"\n    api_key env.OPENAI_API_KEY\n    temperature 0.0\n  }\n}\n\n// High-accuracy OpenAI Chat Completions client for fallbacks\nclient<llm> OpenAIChatReliable {\n  provider openai\n  options {\n    model "gpt-4o"\n    api_key env.OPENAI_API_KEY\n  }\n}\n\n// Anthropic Haiku offers strong instruction following at low latency\nclient<llm> AnthropicHaiku {\n  provider anthropic\n  options {\n    model "claude-3-5-haiku-20241022"\n    api_key env.ANTHROPIC_API_KEY\n    temperature 0.0\n  }\n}\n\n// Primary client â€“ round robin between vetted providers to avoid rate spikes\nclient<llm> MedicalAlertsRoundRobin {\n  provider round-robin\n  options {\n    strategy [\n      OpenAIResponsesStable\n      // AnthropicHaiku\n      ]\n  }\n}\n\n// Try the round-robin path first, fall back to the more capable OpenAI Chat model\nclient<llm> MedicalAlertsFallback {\n  provider fallback\n  options {\n    strategy [MedicalAlertsRoundRobin, OpenAIChatReliable]\n  }\n}\n\n// Conservative retry strategy catches transient network/429 errors\nretry_policy Constant {\n  max_retries 3\n  strategy {\n    type constant_delay\n    delay_ms 250\n  }\n}\n\nretry_policy Exponential {\n  max_retries 2\n  strategy {\n    type exponential_backoff\n    delay_ms 400\n    multiplier 2.0\n    max_delay_ms 8000\n  }\n}\n',
    "document_extractor.baml": 'class AlertType {\n    id string @description("lowercase, underscore-separated string")\n    name string\n    description string\n}\n\nclass MedicalAlert {\n    type AlertType\n    event string @description("A brief description of the alert")\n    date string  @description("As an ISO8601 timestamp (YYYY-MM-DD)")\n}\n\ntemplate_string PrintAlertTypes(alert_types: AlertType[]) #"\n  {% for m in alert_types %}\n    - {{ m.id }}: {{ m.name }} - {{ m.description }}\n  {% endfor %}\n"#\n\nfunction ExtractMedicalAlerts(document:string, alert_types: AlertType[]) -> MedicalAlert[] {\n    client MedicalAlertsFallback\n\n    prompt #"\n        You are a clinical documentation analyst. Extract factual, date-based care reminders from the medical record below.\n\n        Alert taxonomy (id - name - description):\n        {{ PrintAlertTypes(alert_types) }}\n\n        Output requirements:\n        - Respond with **only** valid JSON that matches {{ ctx.output_format }}.\n        - Every alert `type.id` **must** match one of the provided alert_types. If nothing matches, omit the alert.\n        - Use ISO dates (`YYYY-MM-DD`). If a precise date is unclear, skip the alert rather than guessing.\n        - Consolidate duplicate or overlapping statements into a single alert with the most specific due date.\n        - Ignore historical notes that are explicitly marked complete unless a future follow-up is scheduled.\n        - Never invent vaccines, procedures, or dates that are not explicitly supported by the text.\n\n        Verification checklist (follow before responding):\n        1. Have you mapped each alert back to a direct citation in the document?\n        2. Are all dates valid calendar dates in ISO format?\n        3. Did you remove any duplicate, cancelled, or completed items?\n\n        {{ _.role("system") }} Return an empty array (`[]`) when no qualifying alerts are present.\n\n        {{ _.role("user") }} {{ document }}\n    "#\n}',
    "generators.baml": '// This helps use auto generate libraries you can use in the language of\n// your choice. You can have multiple generators if you use multiple languages.\n// Just ensure that the output_dir is different for each generator.\ngenerator target {\n    // Valid values: "python/pydantic", "typescript", "ruby/sorbet", "rest/openapi"\n    output_type "python/pydantic"\n\n    // Where the generated code will be saved (relative to baml_src/)\n    output_dir "../"\n\n    // The version of the BAML package you have installed (e.g. same version as your baml-py or @boundaryml/baml).\n    // The BAML VSCode extension version should also match this version.\n    version "0.211.2"\n\n    // Valid values: "sync", "async"\n    // This controls what `b.FunctionName()` will be (sync or async).\n    default_client_mode sync\n}\n',
    "resume.baml": '// Defining a data model.\nclass Resume {\n  name string\n  email string\n  experience string[]\n  skills string[]\n}\n\n// Create a function to extract the resume from a string.\nfunction ExtractResume(resume: string) -> Resume {\n  // Specify a client as provider/model-name\n  // You can also use custom LLM params with a custom client name from clients.baml like "client CustomGPT5" or "client CustomSonnet4"\n  client "openai-responses/gpt-5-mini" // Set OPENAI_API_KEY to use this client.\n  prompt #"\n    Extract from this content:\n    {{ resume }}\n\n    {{ ctx.output_format }}\n  "#\n}\n\n\n\n// Test the function with a sample resume. Open the VSCode playground to run this.\ntest vaibhav_resume {\n  functions [ExtractResume]\n  args {\n    resume #"\n      Vaibhav Gupta\n      vbv@boundaryml.com\n\n      Experience:\n      - Founder at BoundaryML\n      - CV Engineer at Google\n      - CV Engineer at Microsoft\n\n      Skills:\n      - Rust\n      - C++\n    "#\n  }\n}\n',
}


def get_baml_files():
    return _file_map
